# üîó Guide d'Int√©gration Pipeline Python

Ce guide explique comment int√©grer votre pipeline Python existant avec l'interface web Next.js.

## üìã Pr√©requis

- Node.js 18+
- Python 3.8+
- PyTorch avec CUDA (optionnel)
- Vos mod√®les entra√Æn√©s (.pth)

## üõ†Ô∏è Int√©gration Backend

### Option 1: API Flask/FastAPI (Recommand√©e)

Cr√©ez un serveur Python s√©par√© pour traiter les images:

```python
# api_server.py
from flask import Flask, request, jsonify
import cv2
import numpy as np
import torch
import base64
from io import BytesIO
from PIL import Image

# Importez vos architectures de mod√®les
from your_pipeline import (
    SupervisedDenoisingUNet,
    AggressiveContrastNet, 
    FastRealESRGANGenerator,
    LadderNet
)

app = Flask(__name__)

# Chargez vos mod√®les au d√©marrage
models = load_all_models('cuda' if torch.cuda.is_available() else 'cpu')

@app.route('/process', methods=['POST'])
def process_image():
    try:
        # R√©cup√©rer l'image et param√®tres
        data = request.get_json()
        image_data = data['image']  # Base64
        parameters = data['parameters']
        
        # D√©coder l'image
        image = decode_base64_image(image_data)
        
        # Ex√©cuter votre pipeline
        results = execute_pipeline(image, models, device)
        
        # Encoder les r√©sultats en base64
        processed_image = encode_image_to_base64(results['super_resolution'])
        segmentation_mask = encode_image_to_base64(results['segmentation'])
        
        return jsonify({
            'success': True,
            'processedImage': processed_image,
            'segmentationMask': segmentation_mask,
            'metrics': {
                'psnr': float(results.get('psnr', 0)),
                'ssim': float(results.get('ssim', 0)),
                'dice': float(results.get('dice', 0)),
                'processingTime': float(results.get('time', 0))
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='127.0.0.1', port=5000, debug=True)
```

### Option 2: Subprocess (Plus Simple)

Modifiez `src/app/api/process/route.ts`:

```typescript
import { exec } from 'child_process';
import { promisify } from 'util';
import path from 'path';
import fs from 'fs';

const execAsync = promisify(exec);

export async function POST(request: NextRequest) {
  try {
    // Sauvegarder l'image temporairement
    const formData = await request.formData();
    const image = formData.get('image') as File;
    const parameters = JSON.parse(formData.get('parameters') as string);
    
    const tempDir = path.join(process.cwd(), 'temp');
    const inputPath = path.join(tempDir, `input_${Date.now()}.png`);
    const outputDir = path.join(tempDir, `output_${Date.now()}`);
    
    // Sauvegarder l'image
    const imageBuffer = Buffer.from(await image.arrayBuffer());
    fs.writeFileSync(inputPath, imageBuffer);
    
    // Ex√©cuter votre script Python
    const pythonScript = process.env.PYTHON_SCRIPT_PATH || './pipeline.py';
    const command = `python "${pythonScript}" --input "${inputPath}" --output "${outputDir}" --contrast ${parameters.contrast} --brightness ${parameters.brightness} --noise-reduction ${parameters.noiseReduction}`;
    
    const { stdout, stderr } = await execAsync(command);
    
    // Lire les r√©sultats
    const processedImagePath = path.join(outputDir, 'processed.png');
    const segmentationPath = path.join(outputDir, 'segmentation.png');
    const metricsPath = path.join(outputDir, 'metrics.json');
    
    const processedImage = fs.readFileSync(processedImagePath, 'base64');
    const segmentationMask = fs.readFileSync(segmentationPath, 'base64');
    const metrics = JSON.parse(fs.readFileSync(metricsPath, 'utf8'));
    
    // Nettoyer les fichiers temporaires
    fs.unlinkSync(inputPath);
    fs.rmSync(outputDir, { recursive: true });
    
    return NextResponse.json({
      success: true,
      processedImage: `data:image/png;base64,${processedImage}`,
      segmentationMask: `data:image/png;base64,${segmentationMask}`,
      metrics
    });
    
  } catch (error) {
    console.error('Erreur:', error);
    return NextResponse.json({ error: 'Erreur de traitement' }, { status: 500 });
  }
}
```

## üîß Modification du Pipeline Python

Ajoutez une interface CLI √† votre `pipeline.py`:

```python
import argparse
import json
import os
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(description='Pipeline √©chographique')
    parser.add_argument('--input', required=True, help='Chemin image input')
    parser.add_argument('--output', required=True, help='Dossier de sortie')
    parser.add_argument('--contrast', type=int, default=50, help='Contraste 0-100')
    parser.add_argument('--brightness', type=int, default=50, help='Luminosit√© 0-100')
    parser.add_argument('--noise-reduction', type=int, default=75, help='R√©duction bruit 0-100')
    
    args = parser.parse_args()
    
    # Cr√©er dossier de sortie
    Path(args.output).mkdir(parents=True, exist_ok=True)
    
    # Charger l'image
    input_image = cv2.imread(args.input, cv2.IMREAD_GRAYSCALE)
    
    # Charger les mod√®les
    models = load_all_models('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Ex√©cuter le pipeline avec vos param√®tres
    results = execute_pipeline(input_image, models, device, {
        'contrast': args.contrast / 100.0,
        'brightness': args.brightness / 100.0, 
        'noise_reduction': args.noise_reduction / 100.0
    })
    
    # Sauvegarder les r√©sultats
    cv2.imwrite(os.path.join(args.output, 'processed.png'), 
                (results['super_resolution'] * 255).astype(np.uint8))
    
    # Sauvegarder la segmentation coloris√©e
    colored_seg = colorize_segmentation(results['segmentation'])
    cv2.imwrite(os.path.join(args.output, 'segmentation.png'), 
                cv2.cvtColor(colored_seg, cv2.COLOR_RGB2BGR))
    
    # Sauvegarder les m√©triques
    metrics = {
        'psnr': float(results.get('psnr', 0)),
        'ssim': float(results.get('ssim', 0)),
        'dice': float(results.get('dice', 0)),
        'processingTime': float(results.get('total_time', 0))
    }
    
    with open(os.path.join(args.output, 'metrics.json'), 'w') as f:
        json.dump(metrics, f)

if __name__ == "__main__":
    main()
```

## üöÄ D√©ploiement

### D√©veloppement Local

1. **D√©marrer l'interface Next.js:**
   ```bash
   npm run dev
   ```

2. **D√©marrer le serveur Python (si Option 1):**
   ```bash
   python api_server.py
   ```

### Production

1. **Construire l'interface:**
   ```bash
   npm run build
   npm start
   ```

2. **D√©ployer avec PM2:**
   ```bash
   npm install -g pm2
   pm2 start ecosystem.config.js
   ```

## üìù Configuration

Modifiez `.env.local`:

```env
# Chemin vers votre pipeline Python
PYTHON_SCRIPT_PATH=C:\Users\ASUS\Desktop\Final\pipeline.py

# Chemins des mod√®les
DENOISING_MODEL_PATH=C:\Users\ASUS\Desktop\Final\models\supervised_denoising_best.pth
CONTRAST_MODEL_PATH=C:\Users\ASUS\Desktop\Final\models\aggressive_contrast_best.pth
REALESRGAN_MODEL_PATH=C:\Users\ASUS\Desktop\Final\models\fast_realesrgan_best.pth
LADDERNET_MODEL_PATH=C:\Users\ASUS\Desktop\Final\models\laddernet_best_dice.pth

# Configuration CUDA
USE_GPU=true
CUDA_VISIBLE_DEVICES=0
```

## üß™ Test d'Int√©gration

```bash
# Tester l'API
curl -X POST http://localhost:3000/api/process \
  -F "image=@test_image.png" \
  -F "parameters={\"contrast\":70,\"brightness\":60,\"noiseReduction\":80}"
```

## ‚ö° Optimisations

1. **Cache des mod√®les** - Gardez les mod√®les charg√©s en m√©moire
2. **Queue de traitement** - Utilisez Redis/Bull pour g√©rer les t√¢ches
3. **WebSockets** - Mises √† jour en temps r√©el du progr√®s
4. **GPU sharing** - Gestion intelligente des ressources CUDA

## üîç Debug

- Logs Next.js: `npm run dev` puis v√©rifiez la console
- Logs Python: Ajoutez `print()` dans votre pipeline
- Network: Utilisez les DevTools du navigateur
- Fichiers temp: V√©rifiez `./temp/` pour debug

## üìû Support

Pour toute question sur l'int√©gration, v√©rifiez:
1. Les chemins des mod√®les dans `.env.local`
2. Les permissions d'ex√©cution de Python
3. La compatibilit√© des versions PyTorch
4. L'espace disque pour les fichiers temporaires
